{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df['sentiment'] = df['sentiment'].map({0:0,4:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      "sentiment    1600000 non-null int64\n",
      "text         1596714 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1596714 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      "sentiment    1596714 non-null int64\n",
      "text         1596714 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 36.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/ Dev/ Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data into three sections: train, development and test. Our chosen ratio is 98/1/1 i.e. 98% for the training set, 1% for the development set and 1% for the testing set.\n",
    "* Train set: The dataset used for learning\n",
    "* Development Set: A validation/development dataset is a sample of data held back from training your model that is used to give an estimate of model skill while tuning modelâ€™s hyperparameters.\n",
    "* Test Set: The dataset used to assess the performance of a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text'] #define all other columns except the target variable\n",
    "y = df['sentiment'] #define the target variable\n",
    "\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size = 0.02, random_state = 42)\n",
    "\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, \n",
    "                                                              test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 1564779 entries, where 49.99 are positive and 50.01 are negative\n",
      "Validation set has 15967 entries, where 49.82 are positive and 50.18 are negative\n",
      "Testing set has 15968 entries, where 50.33 are positive and 49.67 are negative\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set has {0} entries, where {1:.2f} are positive and {2:.2f} are negative\".\n",
    "      format(len(x_train),len(x_train[y_train==1])/len(x_train)*100, len(x_train[y_train==0])/len(x_train)*100))\n",
    "print(\"Validation set has {0} entries, where {1:.2f} are positive and {2:.2f} are negative\".\n",
    "      format(len(x_validation),len(x_validation[y_validation==1])/len(x_validation)*100, \n",
    "             len(x_validation[y_validation==0])/len(x_validation)*100))\n",
    "print(\"Testing set has {0} entries, where {1:.2f} are positive and {2:.2f} are negative\".\n",
    "      format(len(x_test),len(x_test[y_test==1])/len(x_test)*100, \n",
    "             len(x_test[y_test==0])/len(x_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the sentiment analysis function of TextBlob as baseline for our project. It will provide us a point of reference to compare our future models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbresult = []\n",
    "for i in x_validation:\n",
    "    tbresult.append(TextBlob(i).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbpred = []\n",
    "for i in tbresult:\n",
    "    if i<0:\n",
    "        tbpred.append(0)\n",
    "    else:\n",
    "        tbpred.append(1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 61.41 %\n"
     ]
    }
   ],
   "source": [
    "conmat = np.array(confusion_matrix(y_validation, tbpred, labels=[1,0]))\n",
    "confusion = pd.DataFrame(conmat, index=['positive', 'negative'], columns=['predicted_positive', 'predicted_negative'])\n",
    "print(\"Accuracy score: {0:.2f} %\".format(accuracy_score(y_validation, tbpred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "          predicted_positive  predicted_negative\n",
      "positive                7136                 818\n",
      "negative                5344                2669\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.33      0.46      8013\n",
      "           1       0.57      0.90      0.70      7954\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     15967\n",
      "   macro avg       0.67      0.62      0.58     15967\n",
      "weighted avg       0.67      0.61      0.58     15967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\")\n",
    "print(classification_report(y_validation, tbpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, TextBlob sentiment analysis yielded 61.41% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline class allows sticking multiple processes into a single scikit-learn estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_accuracy = 0\n",
    "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    if len(x_test[y_test==0])/len(x_test)>0.5:\n",
    "        null_accuracy = len(x_test[y_test==0])/len(x_test)\n",
    "    else:\n",
    "        null_accuracy = 1 - len(x_test[y_test==0])/len(x_test)\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Null accuracy: {0:.2f}%\".format(null_accuracy*100))\n",
    "    print(\"Accuracy: {0:.2f}%\".format(accuracy*100))\n",
    "    if accuracy>null_accuracy:\n",
    "        print(\"Model is {0:.2f}% more accurate than null accuracy\".format((accuracy-null_accuracy)*100))\n",
    "    elif accuracy==null_accuracy:\n",
    "        print(\"Model has the same accuracy as null accuracy\")\n",
    "    else:\n",
    "        print(\"Model is {0:.2f}% less accurate than null accuracy\".format((null_accuracy-accuracy)*100))\n",
    "    print(\"Train and test time: {0:.2f}s\".format(train_test_time))\n",
    "    print(\"-\"*50)\n",
    "    return accuracy, train_test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "lr = LogisticRegression()\n",
    "n_features = np.arange(10000, 100001, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfeature_accuracy_checker(vectorizer = cvec, n_features = n_features, stop_words = None, \n",
    "                              ngram_range = (1,1), classifier = lr):\n",
    "    result = []\n",
    "    print(classifier, \"\\n\")\n",
    "    for n in n_features:\n",
    "        vectorizer.set_params(stop_words = stop_words, max_features = n, ngram_range=ngram_range)\n",
    "        checker_pipeline = Pipeline([('vectorizer', vectorizer), ('classifier', classifier)])\n",
    "        print(\"Validation result for {0} features\".format(n))\n",
    "        nfeature_accuracy, ttime = accuracy_summary(checker_pipeline, x_train, y_train, x_validation, y_validation)\n",
    "        result.append((n, nfeature_accuracy, ttime))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT FOR UNIGRAM WITHOUT STOP WORDS\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False) \n",
      "\n",
      "Validation result for 10000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 77.27%\n",
      "Model is 27.08% more accurate than null accuracy\n",
      "Train and test time: 101.11s\n",
      "--------------------------------------------------\n",
      "Validation result for 20000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 77.52%\n",
      "Model is 27.33% more accurate than null accuracy\n",
      "Train and test time: 118.81s\n",
      "--------------------------------------------------\n",
      "Validation result for 30000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 77.54%\n",
      "Model is 27.36% more accurate than null accuracy\n",
      "Train and test time: 138.48s\n",
      "--------------------------------------------------\n",
      "Validation result for 40000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 77.52%\n",
      "Model is 27.34% more accurate than null accuracy\n",
      "Train and test time: 163.33s\n",
      "--------------------------------------------------\n",
      "Validation result for 50000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 77.50%\n",
      "Model is 27.32% more accurate than null accuracy\n",
      "Train and test time: 144.55s\n",
      "--------------------------------------------------\n",
      "Validation result for 60000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 77.56%\n",
      "Model is 27.38% more accurate than null accuracy\n",
      "Train and test time: 123.57s\n",
      "--------------------------------------------------\n",
      "Validation result for 70000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 77.58%\n",
      "Model is 27.39% more accurate than null accuracy\n",
      "Train and test time: 120.93s\n",
      "--------------------------------------------------\n",
      "Validation result for 80000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 77.57%\n",
      "Model is 27.39% more accurate than null accuracy\n",
      "Train and test time: 124.25s\n",
      "--------------------------------------------------\n",
      "Validation result for 90000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 77.57%\n",
      "Model is 27.39% more accurate than null accuracy\n",
      "Train and test time: 134.20s\n",
      "--------------------------------------------------\n",
      "Validation result for 100000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 77.55%\n",
      "Model is 27.37% more accurate than null accuracy\n",
      "Train and test time: 133.97s\n",
      "--------------------------------------------------\n",
      "Wall time: 21min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"RESULT FOR UNIGRAM WITHOUT STOP WORDS\\n\")\n",
    "feature_result_unigram = nfeature_accuracy_checker(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT FOR UNIGRAM WITH STOP WORDS\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False) \n",
      "\n",
      "Validation result for 10000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 79.73%\n",
      "Model is 29.55% more accurate than null accuracy\n",
      "Train and test time: 138.26s\n",
      "--------------------------------------------------\n",
      "Validation result for 20000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 79.90%\n",
      "Model is 29.71% more accurate than null accuracy\n",
      "Train and test time: 181.06s\n",
      "--------------------------------------------------\n",
      "Validation result for 30000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 79.98%\n",
      "Model is 29.80% more accurate than null accuracy\n",
      "Train and test time: 190.65s\n",
      "--------------------------------------------------\n",
      "Validation result for 40000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 80.02%\n",
      "Model is 29.83% more accurate than null accuracy\n",
      "Train and test time: 169.35s\n",
      "--------------------------------------------------\n",
      "Validation result for 50000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 80.13%\n",
      "Model is 29.95% more accurate than null accuracy\n",
      "Train and test time: 190.28s\n",
      "--------------------------------------------------\n",
      "Validation result for 60000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 80.22%\n",
      "Model is 30.04% more accurate than null accuracy\n",
      "Train and test time: 264.07s\n",
      "--------------------------------------------------\n",
      "Validation result for 70000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 80.20%\n",
      "Model is 30.01% more accurate than null accuracy\n",
      "Train and test time: 239.14s\n",
      "--------------------------------------------------\n",
      "Validation result for 80000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 80.27%\n",
      "Model is 30.08% more accurate than null accuracy\n",
      "Train and test time: 284.82s\n",
      "--------------------------------------------------\n",
      "Validation result for 90000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 80.28%\n",
      "Model is 30.09% more accurate than null accuracy\n",
      "Train and test time: 292.64s\n",
      "--------------------------------------------------\n",
      "Validation result for 100000 features\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 80.30%\n",
      "Model is 30.12% more accurate than null accuracy\n",
      "Train and test time: 280.12s\n",
      "--------------------------------------------------\n",
      "Wall time: 37min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"RESULT FOR UNIGRAM WITH STOP WORDS\\n\")\n",
    "feature_result_unigram_stop = nfeature_accuracy_checker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
