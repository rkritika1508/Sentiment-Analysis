{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_tweets.csv')\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df['sentiment'] = df['sentiment'].map({0:0,4:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      "sentiment    1600000 non-null int64\n",
      "text         1596714 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1596714 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      "sentiment    1596714 non-null int64\n",
      "text         1596714 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 36.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text'] #define all other columns except the target variable\n",
    "y = df['sentiment'] #define the target variable\n",
    "\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size = 0.02, random_state = 42)\n",
    "\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, \n",
    "                                                              test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc='progress-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import multiprocessing\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = model.docvecs[prefix]\n",
    "        n += 1\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concat_vectors(model1, model2, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = np.append(model1.docvecs[prefix], model2.docvecs[prefix])\n",
    "        n += 1\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It automatically detects common phrases – multi-word expressions/ word n-grams – from a stream of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised_train = [t.split() for t in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "phrases = Phrases(tokenised_train)\n",
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['last', 'time', 'with', 'nutella', 'and', 'vanilla_ice', 'cream', 'sadface']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram[['last', 'time', 'with', 'nutella', 'and', 'vanilla', 'ice', 'cream', 'sadface']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelize_tweets_bg(tweets, label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(TaggedDocument(bigram[t.split()], [prefix + '_%s' % i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x = pd.concat([x_train, x_validation, x_test])\n",
    "all_x_w2v_bg = labelize_tweets_bg(all_x, 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram DBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2826772.21it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dbow = Doc2Vec(dm=0, vector_size=100, negative=5, workers=cores, min_count=2, alpha = 0.065, min_alpha=0.065)\n",
    "model_bg_dbow.build_vocab([x for x in tqdm(all_x_w2v_bg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2712603.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2860718.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2989492.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3037065.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3005243.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3111828.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2482146.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3076768.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2986842.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2808588.23it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3080179.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2951073.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3059910.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3048680.68it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3042333.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3037928.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2964783.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2065697.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2937397.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3136008.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1816095.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2772242.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2733038.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3117118.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3115320.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3109068.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3092479.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3059369.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2879303.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2909413.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_bg_dbow.train(utils.shuffle([x for x in tqdm(all_x_w2v_bg)]), total_examples=len(all_x_w2v_bg), epochs=1)\n",
    "    model_bg_dbow.alpha -= 0.002\n",
    "    model_bg_dbow.min_alpha = model_bg_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dbow_bg = get_vectors(model_bg_dbow, x_train, 100)\n",
    "validation_vecs_dbow_bg = get_vectors(model_bg_dbow, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg_dbow.save('d2v_model_bg_dbow.doc2vec')\n",
    "model_bg_dbow = Doc2Vec.load('d2v_model_bg_dbow.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_bg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744222458821319"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dbow_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg.append(clf.score(validation_vecs_dbow_bg, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram DMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1596714/1596714 [00:04<00:00, 398963.84it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dmc = Doc2Vec(dm=1, dm_concat=1, vector_size=100, negative=5, window=2,\n",
    "                       workers=cores, min_count=2, alpha = 0.065, min_alpha=0.065)\n",
    "model_bg_dmc.build_vocab([x for x in tqdm(all_x_w2v_bg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1796547.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1807192.26it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1825734.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1869919.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:01<00:00, 1454694.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1973767.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2229107.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1888799.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1968944.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1639358.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1801465.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1752138.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1792123.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1797666.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1794276.28it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1799282.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1809001.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1799634.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1817354.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3202843.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3314702.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3013577.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2860820.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3137930.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3340419.71it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3221238.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3330860.10it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3374075.15it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3320474.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3182867.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_bg_dmc.train(utils.shuffle([x for x in tqdm(all_x_w2v_bg)]), total_examples=len(all_x_w2v_bg), epochs=1)\n",
    "    model_bg_dmc.alpha -= 0.002\n",
    "    model_bg_dmc.min_alpha = model_bg_dmc.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dmc_bg = get_vectors(model_bg_dmc, x_train, 100)\n",
    "validation_vecs_dmc_bg = get_vectors(model_bg_dmc, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmc_bg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6703826642450054"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dmc_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg.append(clf.score(validation_vecs_dmc_bg, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg_dmc.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram DMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1791366.88it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=100, negative=5, window=4, workers=cores,\n",
    "                        min_count=2, alpha = 0.065, min_alpha=0.065)\n",
    "model_bg_dmm.build_vocab([x for x in tqdm(all_x_w2v_bg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1812452.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1805580.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1967964.12it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1820982.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1834641.54it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1892224.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1868259.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1837380.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1875937.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1941032.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1938652.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1879591.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1931437.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2003646.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1893116.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1838541.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2836564.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2870763.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2938407.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3158099.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2938055.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3297139.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2672700.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3059821.12it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3126920.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3406318.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3119011.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3003728.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2943000.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2974277.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 19min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_bg_dmm.train(utils.shuffle([x for x in tqdm(all_x_w2v_bg)]), total_examples=len(all_x_w2v_bg), epochs=1)\n",
    "    model_bg_dmm.alpha -= 0.002\n",
    "    model_bg_dmm.min_alpha = model_bg_dmm.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dmm_bg = get_vectors(model_bg_dmm, x_train, 100)\n",
    "validation_vecs_dmm_bg = get_vectors(model_bg_dmm, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmm_bg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.740840483497213"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dmm_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg_dmm.save('d2v_model_bg_dmm.doc2vec')\n",
    "model_bg_dmm = Doc2Vec.load('d2v_model_bg_dmm.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg.append(clf.score(validation_vecs_dmm_bg, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram DBOW + DMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_bg_dbow_dmc = get_concat_vectors(model_bg_dbow, model_bg_dmc, x_train, 200)\n",
    "validation_vecs_bg_dbow_dmc = get_concat_vectors(model_bg_dbow, model_bg_dmc, x_validation, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_bg_dbow_dmc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7519258470595603"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_bg_dbow_dmc, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg.append(clf.score(validation_vecs_bg_dbow_dmc, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram DBOW + DMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_bg_dbow_dmm = get_concat_vectors(model_bg_dbow, model_bg_dmm, x_train, 200)\n",
    "validation_vecs_bg_dbow_dmm = get_concat_vectors(model_bg_dbow, model_bg_dmm, x_validation, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_bg_dbow_dmm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7617586271685352"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_bg_dbow_dmm, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg.append(clf.score(validation_vecs_bg_dbow_dmm, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.744222458821319,\n",
       " 0.6703826642450054,\n",
       " 0.740840483497213,\n",
       " 0.7519258470595603,\n",
       " 0.7617586271685352]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the accuracy for Bigrams using Logistic Regression is as follows:\n",
    "\n",
    "* DBOW - 74.4%\n",
    "\n",
    "* DMC - 67.04%\n",
    "\n",
    "* DMM - 74.08%\n",
    "\n",
    "* DBOW + DMC - 75.19%\n",
    "\n",
    "* DBOW + DMM - 76.17%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tg_phrases = Phrases(bigram[tokenised_train])\n",
    "trigram = Phraser(tg_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['last', 'time', 'with', 'nutella', 'and', 'vanilla_ice_cream', 'sadface']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram[bigram[['last', 'time', 'with', 'nutella', 'and', 'vanilla', 'ice', 'cream', 'sadface']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelize_tweets_tg(tweets, label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(TaggedDocument(trigram[bigram[t.split()]], [prefix + '_%s' % i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x = pd.concat([x_train, x_validation, x_test])\n",
    "all_x_w2v_tg = labelize_tweets_tg(all_x, 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram DBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2031394.03it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_tg_dbow = Doc2Vec(dm=0, vector_size=100, negative=5, workers=cores, min_count=2, alpha = 0.065, min_alpha=0.065)\n",
    "model_tg_dbow.build_vocab([x for x in tqdm(all_x_w2v_tg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:01<00:00, 1566082.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2965002.23it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2630626.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3268249.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3150780.61it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3103788.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3012249.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2949755.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3056055.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2144680.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:01<00:00, 1591223.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1791580.62it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:01<00:00, 1581226.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1800125.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2109231.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1811973.26it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:01<00:00, 1489983.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:01<00:00, 1561581.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1855709.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1863936.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2074233.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:01<00:00, 1452569.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1645304.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1619313.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:01<00:00, 1582060.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1642059.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1723378.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1819738.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1697069.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1743282.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49min 22s\n",
      "Parser   : 278 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_tg_dbow.train(utils.shuffle([x for x in tqdm(all_x_w2v_tg)]), total_examples=len(all_x_w2v_tg), epochs=1)\n",
    "    model_tg_dbow.alpha -= 0.002\n",
    "    model_tg_dbow.min_alpha = model_tg_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dbow_tg = get_vectors(model_tg_dbow, x_train, 100)\n",
    "validation_vecs_dbow_tg = get_vectors(model_tg_dbow, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(train_vecs_dbow_tg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7418425502599111"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dbow_tg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tg.append(clf.score(validation_vecs_dbow_tg, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tg_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7418425502599111]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram DMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3320069.09it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_tg_dmc = Doc2Vec(dm=1, dm_concat=1, vector_size=100, negative=5, window=2,\n",
    "                       workers=cores, min_count=2, alpha = 0.065, min_alpha=0.065)\n",
    "model_tg_dmc.build_vocab([x for x in tqdm(all_x_w2v_tg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:01<00:00, 1554354.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2797015.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2702619.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3386126.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2890802.12it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2833046.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3056811.41it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3150484.17it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3086547.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3167562.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3298718.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3216097.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3133175.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3065760.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3238634.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3154984.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3118847.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3191610.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2515533.15it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2951650.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2930788.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2511914.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3032181.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2953843.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3165947.99it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1975712.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3100786.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2992577.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3042054.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2889068.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30min 26s\n",
      "Parser   : 571 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_tg_dmc.train(utils.shuffle([x for x in tqdm(all_x_w2v_tg)]), total_examples=len(all_x_w2v_tg), epochs=1)\n",
    "    model_tg_dmc.alpha -= 0.002\n",
    "    model_tg_dmc.min_alpha = model_tg_dmc.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dmc_tg = get_vectors(model_tg_dmc, x_train, 100)\n",
    "validation_vecs_dmc_tg = get_vectors(model_tg_dmc, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(train_vecs_dmc_tg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6647460387048287"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dmc_tg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tg.append(clf.score(validation_vecs_dmc_tg, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tg_dmc.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7418425502599111, 0.6647460387048287]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram DMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1730915.43it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_tg_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=100, negative=5, window=4, workers=cores,\n",
    "                        min_count=2, alpha = 0.065, min_alpha=0.065)\n",
    "model_tg_dmm.build_vocab([x for x in tqdm(all_x_w2v_tg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1596714/1596714 [00:01<00:00, 810624.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:01<00:00, 1562737.54it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:01<00:00, 1432354.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1713568.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:01<00:00, 1436303.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1736364.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1859373.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 1950328.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2974312.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3015686.51it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2635754.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3145527.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3232456.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3234175.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3078806.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3065633.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3151708.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3195581.09it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2744669.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3021906.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3195550.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3164015.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2780796.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3176567.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3108687.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2975964.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3090703.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3145349.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 2894914.51it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596714/1596714 [00:00<00:00, 3137572.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 4min 7s\n",
      "Parser   : 425 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_tg_dmm.train(utils.shuffle([x for x in tqdm(all_x_w2v_tg)]), total_examples=len(all_x_w2v_tg), epochs=1)\n",
    "    model_tg_dmm.alpha -= 0.002\n",
    "    model_tg_dmm.min_alpha = model_tg_dmm.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dmm_tg = get_vectors(model_tg_dmm, x_train, 100)\n",
    "validation_vecs_dmm_tg = get_vectors(model_tg_dmm, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(train_vecs_dmm_tg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7373958790004385"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dmm_tg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tg.append(clf.score(validation_vecs_dmm_tg, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tg_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7418425502599111, 0.6647460387048287, 0.7373958790004385]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram DBOW + DMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_tg_dbow_dmc = get_concat_vectors(model_tg_dbow, model_tg_dmc, x_train, 200)\n",
    "validation_vecs_tg_dbow_dmc = get_concat_vectors(model_tg_dbow, model_tg_dmc, x_validation, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.2 s\n",
      "Parser   : 575 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(train_vecs_tg_dbow_dmc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7504227469155133"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_tg_dbow_dmc, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tg.append(clf.score(validation_vecs_tg_dbow_dmc, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram DBOW + DMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_tg_dbow_dmm = get_concat_vectors(model_tg_dbow, model_tg_dmm, x_train, 200)\n",
    "validation_vecs_tg_dbow_dmm = get_concat_vectors(model_tg_dbow, model_tg_dmm, x_validation, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 45.4 s\n",
      "Parser   : 202 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(train_vecs_tg_dbow_dmm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7601302686791508"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_tg_dbow_dmm, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tg.append(clf.score(validation_vecs_tg_dbow_dmm, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7418425502599111,\n",
       " 0.6647460387048287,\n",
       " 0.7373958790004385,\n",
       " 0.7504227469155133,\n",
       " 0.7601302686791508]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the accuracy for Trigrams using Logistic Regression is as follows:\n",
    "\n",
    "* DBOW - 74.18%\n",
    "\n",
    "* DMC - 66.47%\n",
    "\n",
    "* DMM - 73.74%\n",
    "\n",
    "* DBOW + DMC - 75.04%\n",
    "\n",
    "* DBOW + DMM - 76.01%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.744222458821319,\n",
       " 0.6703826642450054,\n",
       " 0.740840483497213,\n",
       " 0.7519258470595603,\n",
       " 0.7617586271685352]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ug = [0.7360806663743972, 0.6664996555395504, 0.7301935241435461, 0.7482307258721113, 0.7534915763762761]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [(model_ug), (model_bg), (model_tg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['DBOW', 'DMC', 'DMM', 'DBOW + DMC', 'DBOW + DMM']\n",
    "df = pd.DataFrame.from_records(model, columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBOW</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DMM</th>\n",
       "      <th>DBOW + DMC</th>\n",
       "      <th>DBOW + DMM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.736081</td>\n",
       "      <td>0.666500</td>\n",
       "      <td>0.730194</td>\n",
       "      <td>0.748231</td>\n",
       "      <td>0.753492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.744222</td>\n",
       "      <td>0.670383</td>\n",
       "      <td>0.740840</td>\n",
       "      <td>0.751926</td>\n",
       "      <td>0.761759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741843</td>\n",
       "      <td>0.664746</td>\n",
       "      <td>0.737396</td>\n",
       "      <td>0.750423</td>\n",
       "      <td>0.760130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DBOW       DMC       DMM  DBOW + DMC  DBOW + DMM\n",
       "0  0.736081  0.666500  0.730194    0.748231    0.753492\n",
       "1  0.744222  0.670383  0.740840    0.751926    0.761759\n",
       "2  0.741843  0.664746  0.737396    0.750423    0.760130"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DBOW</th>\n",
       "      <td>0.736081</td>\n",
       "      <td>0.744222</td>\n",
       "      <td>0.741843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMC</th>\n",
       "      <td>0.666500</td>\n",
       "      <td>0.670383</td>\n",
       "      <td>0.664746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMM</th>\n",
       "      <td>0.730194</td>\n",
       "      <td>0.740840</td>\n",
       "      <td>0.737396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBOW + DMC</th>\n",
       "      <td>0.748231</td>\n",
       "      <td>0.751926</td>\n",
       "      <td>0.750423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBOW + DMM</th>\n",
       "      <td>0.753492</td>\n",
       "      <td>0.761759</td>\n",
       "      <td>0.760130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2\n",
       "DBOW        0.736081  0.744222  0.741843\n",
       "DMC         0.666500  0.670383  0.664746\n",
       "DMM         0.730194  0.740840  0.737396\n",
       "DBOW + DMC  0.748231  0.751926  0.750423\n",
       "DBOW + DMM  0.753492  0.761759  0.760130"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unigram</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DBOW</th>\n",
       "      <td>0.736081</td>\n",
       "      <td>0.744222</td>\n",
       "      <td>0.741843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMC</th>\n",
       "      <td>0.666500</td>\n",
       "      <td>0.670383</td>\n",
       "      <td>0.664746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMM</th>\n",
       "      <td>0.730194</td>\n",
       "      <td>0.740840</td>\n",
       "      <td>0.737396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBOW + DMC</th>\n",
       "      <td>0.748231</td>\n",
       "      <td>0.751926</td>\n",
       "      <td>0.750423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBOW + DMM</th>\n",
       "      <td>0.753492</td>\n",
       "      <td>0.761759</td>\n",
       "      <td>0.760130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Unigram    Bigram   Trigram\n",
       "DBOW        0.736081  0.744222  0.741843\n",
       "DMC         0.666500  0.670383  0.664746\n",
       "DMM         0.730194  0.740840  0.737396\n",
       "DBOW + DMC  0.748231  0.751926  0.750423\n",
       "DBOW + DMM  0.753492  0.761759  0.760130"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['Unigram', 'Bigram', 'Trigram']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the best performing model is Bigram DBOW + DMM with an accuracy of 76.17%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmscalar = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg_dmm = Doc2Vec.load('d2v_model_bg_dmm.doc2vec')\n",
    "model_bg_dbow = Doc2Vec.load('d2v_model_bg_dbow.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_bg_dbow_dmm = get_concat_vectors(model_bg_dbow, model_bg_dmm, x_train, 200)\n",
    "validation_vecs_bg_dbow_dmm = get_concat_vectors(model_bg_dbow, model_bg_dmm, x_validation, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_bigram_train = mmscalar.fit_transform(train_vecs_bg_dbow_dmm)\n",
    "d2v_bigram_valid = mmscalar.fit_transform(validation_vecs_bg_dbow_dmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Perceptron, PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Logistic Regression', 'Ridge Classifier', 'Perceptron', 'Passive Aggressive Classifier', 'Multinomial NB', \n",
    "          'Gaussian NB', 'Nearest Centroid']\n",
    "classifiers = [LogisticRegression(solver='lbfgs'), RidgeClassifier(), Perceptron(), PassiveAggressiveClassifier(), \n",
    "              MultinomialNB(), GaussianNB(), NearestCentroid()]\n",
    "zipped_clf = zip(names, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_accuracy = 0\n",
    "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    if len(x_test[y_test==0])/len(x_test)>0.5:\n",
    "        null_accuracy = len(x_test[y_test==0])/len(x_test)\n",
    "    else:\n",
    "        null_accuracy = 1 - len(x_test[y_test==0])/len(x_test)\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Null accuracy: {0:.2f}%\".format(null_accuracy*100))\n",
    "    print(\"Accuracy: {0:.2f}%\".format(accuracy*100))\n",
    "    if accuracy>null_accuracy:\n",
    "        print(\"Model is {0:.2f}% more accurate than null accuracy\".format((accuracy-null_accuracy)*100))\n",
    "    elif accuracy==null_accuracy:\n",
    "        print(\"Model has the same accuracy as null accuracy\")\n",
    "    else:\n",
    "        print(\"Model is {0:.2f}% less accurate than null accuracy\".format((null_accuracy-accuracy)*100))\n",
    "    print(\"Train and test time: {0:.2f}s\".format(train_test_time))\n",
    "    print(\"-\"*50)\n",
    "    return accuracy, train_test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_comparator(train, validation, classifier = zipped_clf):\n",
    "    result = []\n",
    "    for n, c in classifier:\n",
    "        pipeline = Pipeline([('classifier', c)])\n",
    "        print('Validation result for {}\\n'.format(n), c)\n",
    "        clf_accuracy, ttime = accuracy_summary(pipeline, train, y_train, validation, y_validation)\n",
    "        result.append((n, clf_accuracy, ttime))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result for Logistic Regression\n",
      " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 75.33%\n",
      "Model is 25.15% more accurate than null accuracy\n",
      "Train and test time: 38.13s\n",
      "--------------------------------------------------\n",
      "Validation result for Ridge Classifier\n",
      " RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "        tol=0.001)\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 75.21%\n",
      "Model is 25.03% more accurate than null accuracy\n",
      "Train and test time: 7.07s\n",
      "--------------------------------------------------\n",
      "Validation result for Perceptron\n",
      " Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=None,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 65.51%\n",
      "Model is 15.33% more accurate than null accuracy\n",
      "Train and test time: 6.22s\n",
      "--------------------------------------------------\n",
      "Validation result for Passive Aggressive Classifier\n",
      " PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              early_stopping=False, fit_intercept=True, loss='hinge',\n",
      "              max_iter=None, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
      "              random_state=None, shuffle=True, tol=None,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 50.18%\n",
      "Accuracy: 69.44%\n",
      "Model is 19.26% more accurate than null accuracy\n",
      "Train and test time: 8.03s\n",
      "--------------------------------------------------\n",
      "Validation result for Multinomial NB\n",
      " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 74.10%\n",
      "Model is 23.92% more accurate than null accuracy\n",
      "Train and test time: 1.46s\n",
      "--------------------------------------------------\n",
      "Validation result for Gaussian NB\n",
      " GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 62.33%\n",
      "Model is 12.15% more accurate than null accuracy\n",
      "Train and test time: 8.85s\n",
      "--------------------------------------------------\n",
      "Validation result for Nearest Centroid\n",
      " NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "Null accuracy: 50.18%\n",
      "Accuracy: 73.86%\n",
      "Model is 23.68% more accurate than null accuracy\n",
      "Train and test time: 2.79s\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Logistic Regression', 0.7533036888582701, 38.13342475891113),\n",
       " ('Ridge Classifier', 0.7521137345775663, 7.0673301219940186),\n",
       " ('Perceptron', 0.6551011461138598, 6.21948504447937),\n",
       " ('Passive Aggressive Classifier', 0.6944322665497589, 8.030767917633057),\n",
       " ('Multinomial NB', 0.7410283710152189, 1.456697702407837),\n",
       " ('Gaussian NB', 0.6233481555708649, 8.85085940361023),\n",
       " ('Nearest Centroid', 0.738648462453811, 2.790031671524048)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_comparator(d2v_bigram_train, d2v_bigram_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
